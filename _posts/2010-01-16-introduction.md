---
title: Introduction
top: true
---

Along with the now widespread availability of unmanned aerial vehicles (UAVs), large volumes of aerial videos have been produced. It is unrealistic for humans to screen such big data and understand their contents. Hence methodological research on the automatic understanding of UAV videos is of paramount importance. In this work, we introduce a novel task of event recognition in unconstrained aerial videos in the remote sensing community and present a large-scale, human-annotated dataset, named ERA (Event Recognition in Aerial videos), consisting of 2,866 videos each with a label from 25 different classes corresponding to an event unfolding 5 seconds. The ERA dataset is designed to have a significant intra-class variation and inter-class similarity and captures dynamic events in different environments and at different scales. Moreover, in order to provide a benchmark for this task, we extensively evaluate existing deep networks. We expect that the ERA dataset will facilitate further progress in automatic aerial video comprehension.
